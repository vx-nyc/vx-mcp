{
  "name": "@vesselnyc/mcp-server",
  "version": "0.2.1",
  "description": "Give your AI persistent memory. MCP server that connects Claude, Cursor, Windsurf, and VS Code to VX â€” your personal knowledge layer that remembers everything.",
  "main": "dist/index.js",
  "bin": {
    "vx-mcp": "./dist/index.js"
  },
  "type": "module",
  "scripts": {
    "build": "tsc",
    "dev": "tsc --watch",
    "start": "node dist/index.js",
    "prepublishOnly": "npm run build"
  },
  "keywords": [
    "mcp",
    "model-context-protocol",
    "modelcontextprotocol",
    "ai",
    "ai-memory",
    "memory",
    "persistent-memory",
    "context",
    "context-window",
    "claude",
    "claude-desktop",
    "cursor",
    "windsurf",
    "vscode",
    "continue",
    "llm",
    "rag",
    "retrieval",
    "knowledge-base",
    "knowledge-graph",
    "embeddings",
    "semantic-search",
    "vector-database",
    "long-term-memory",
    "ai-tools",
    "developer-tools",
    "anthropic",
    "openai",
    "gpt"
  ],
  "author": {
    "name": "Vessel Tech Inc",
    "url": "https://vessel.nyc"
  },
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/vx-nyc/vx-mcp.git"
  },
  "homepage": "https://vessel.nyc",
  "bugs": {
    "url": "https://github.com/vx-nyc/vx-mcp/issues"
  },
  "funding": {
    "type": "github",
    "url": "https://github.com/sponsors/vx-nyc"
  },
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.0.0"
  },
  "devDependencies": {
    "@types/node": "^22.0.0",
    "typescript": "^5.7.0"
  },
  "engines": {
    "node": ">=18"
  },
  "files": [
    "dist",
    "README.md"
  ]
}
